{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from polar import PolarCode,get_frozen\n",
    "from reliability_sequence import Reliability_Sequence\n",
    "from utils import errors_ber,errors_bler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "N = 2**n \n",
    "K = 3\n",
    "snr = 1\n",
    "batch_size = 1\n",
    "num_samples = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data(num_samples, batch_size, n, K, snr):\n",
    "    msg_bits_list = []\n",
    "    bpsk_list = []\n",
    "    codeword_list = []\n",
    "    corrupted_codeword_list = []\n",
    "\n",
    "    # Loop to generate data samples\n",
    "    for i in range(num_samples):\n",
    "        msg_bits = (torch.rand(batch_size, K) > 0.5).float()\n",
    "        bpsk = 1 - 2 * msg_bits\n",
    "\n",
    "        polar = PolarCode(n, K, Fr=None, use_cuda=True, hard_decision=True)\n",
    "        codeword = polar.encode(bpsk)\n",
    "        corrupted_codewords = polar.channel(codeword, snr)\n",
    "\n",
    "        msg_bits_list.append(msg_bits.cpu().numpy())\n",
    "        bpsk_list.append(bpsk.cpu().numpy())\n",
    "        codeword_list.append(codeword.cpu().numpy())\n",
    "        corrupted_codeword_list.append(corrupted_codewords.cpu().numpy())\n",
    "\n",
    "    filename = f\"polar_dataset_N{2**n}_K{K}_SNR{snr}_bs{batch_size}.npz\"\n",
    "    np.savez(f\"polar_dataset_N{2**n}_K{K}_SNR{snr}_bs{batch_size}.npz\", msg_bits=msg_bits_list, corrupted_codeword=corrupted_codeword_list,bpsk = bpsk_list,codeword=codeword_list)\n",
    "    print(f\"Dataset saved as {filename}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as polar_dataset_N16_K9_SNR-1_bs1.npz\n"
     ]
    }
   ],
   "source": [
    "create_data(num_samples,batch_size,n,K,snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load('polar_dataset_N8_K3_SNR1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 207.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "Fr = get_frozen(N, K,rs=Reliability_Sequence)\n",
    "polar = PolarCode(n, K, Fr = Fr,use_cuda=False,hard_decision=True)\n",
    "device = 'cpu'\n",
    "ber_SC_total=0\n",
    "bler_SC_total=0\n",
    "x=10000\n",
    "for bpsk_bits, corrupted_codeword in tqdm(zip(df['bpsk'][:x], df['corrupted_codeword'][:x]),total=len(df['bpsk'][:x])):\n",
    "    bpsk_tensor = torch.tensor(bpsk_bits, dtype=torch.float32,device=device)\n",
    "    corrupted_codeword_tensor = torch.tensor(corrupted_codeword, dtype=torch.float32,device=device)\n",
    "\n",
    "    SC_llrs, decoded_SC_msg_bits = polar.sc_decode_new(corrupted_codeword_tensor, snr=snr)\n",
    "    ber_SC = errors_ber(bpsk_tensor,decoded_SC_msg_bits.sign()).item()\n",
    "    bler_SC = errors_bler(bpsk_tensor,decoded_SC_msg_bits.sign()).item()\n",
    "\n",
    "    ber_SC_total+=ber_SC\n",
    "    bler_SC_total+=bler_SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1., -1.]]),\n",
       " tensor([[-0.5889, -1.5760,  0.5610, -1.0886, -0.2946, -2.1059, -1.6572, -2.8287]]),\n",
       " tensor([[ 1.,  1., -1.]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_SC_msg_bits, corrupted_codeword_tensor, bpsk_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03466666740179062, 0.057)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber_SC_total/len(df['msg_bits'][:x]),bler_SC_total/len(df['msg_bits'][:x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self,N,K,hidden_size,rs):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.K = K\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.frozen_positions = get_frozen(self.N, self.K, rs)\n",
    "        self.frozen_mask = torch.full((N,), -1, dtype=torch.int8)\n",
    "        # self.frozen_mask = torch.zeros(N,dtype=torch.bool)\n",
    "        self.frozen_mask[self.frozen_positions] = 1\n",
    "        self.lstms = nn.ModuleList([\n",
    "            nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "            for _ in range(N)\n",
    "        ])\n",
    "        self.fcs= nn.ModuleList([\n",
    "            nn.Linear(hidden_size, 1) for _ in range(N)\n",
    "        ])\n",
    "    \n",
    "    def forward(self,corrupted_codeword):\n",
    "        batch_size = corrupted_codeword.size(0)\n",
    "        device = corrupted_codeword.device\n",
    "        x = corrupted_codeword.unsqueeze(-1) if corrupted_codeword.dim() == 2 else corrupted_codeword\n",
    "\n",
    "        h0 = [torch.zeros(1, batch_size, self.hidden_size, device=device) for _ in range(self.N)]\n",
    "        c0 = [torch.zeros(1, batch_size, self.hidden_size, device=device) for _ in range(self.N)]\n",
    "\n",
    "        decoded_outputs = []\n",
    "        for i in range(self.N):\n",
    "            output, (h0[i], c0[i]) = self.lstms[i](x, (h0[i], c0[i]))\n",
    "            decoded_bits = self.fcs[i](output).squeeze(-1)\n",
    "            decoded_outputs.append(decoded_bits)\n",
    "            x = corrupted_codeword + (self.frozen_mask.float().to(device)*decoded_bits.sign()) #current logic\n",
    "            x = x.unsqueeze(-1)\n",
    "        \n",
    "        decoded_outputs = torch.stack(decoded_outputs,dim=1)\n",
    "        # non_frozen_mask = ~self.frozen_mask\n",
    "        non_frozen_mask = (self.frozen_mask == -1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        final_predictions = decoded_outputs[:,-1,non_frozen_mask]\n",
    "\n",
    "        return decoded_outputs, final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = LSTMDecoder(N=N,K=K,hidden_size=32,rs=Reliability_Sequence).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ber_bler(predictions, targets):\n",
    "    \"\"\" Calculate BER and BLER using errors_ber and errors_bler functions. \"\"\"\n",
    "    ber = errors_ber(targets, predictions.sign()).item()\n",
    "    bler = errors_bler(targets, predictions.sign()).item()\n",
    "    return ber, bler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:10<00:00, 88.61it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 89.08it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 88.76it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 87.24it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 90.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 0.6027, BER: 0.3378, BLER: 0.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:10<00:00, 89.03it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 90.94it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.49it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.55it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Loss: 0.5770, BER: 0.3052, BLER: 0.6744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:10<00:00, 86.59it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 88.31it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 86.48it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.21it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 84.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 0.5437, BER: 0.2800, BLER: 0.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:09<00:00, 90.27it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.38it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.06it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.73it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 0.4969, BER: 0.2319, BLER: 0.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:09<00:00, 92.72it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.87it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.06it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.57it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 93.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Loss: 0.4424, BER: 0.2111, BLER: 0.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:09<00:00, 92.00it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.66it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.78it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 92.12it/s]\n",
      "100%|██████████| 900/900 [00:09<00:00, 91.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.3797, BER: 0.1848, BLER: 0.4467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "data_len = len(df['msg_bits'][:900])\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_ber,total_bler =0,0\n",
    "    for msg_bits, corrupted_codeword in tqdm(zip(df['msg_bits'][:900], df['corrupted_codeword'][:900]),total=data_len):\n",
    "        msg_tensor = torch.tensor(msg_bits, dtype=torch.float32).to(device)\n",
    "        corrupted_codeword_tensor = torch.tensor(corrupted_codeword, dtype=torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        decoded_outputs, final_predictions = model(corrupted_codeword_tensor)\n",
    "        loss = criterion(final_predictions,msg_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+= loss.item()\n",
    "\n",
    "        ber, bler = calculate_ber_bler((final_predictions>=0).float(), msg_tensor)\n",
    "        total_ber += ber\n",
    "        total_bler += bler\n",
    "    avg_loss = total_loss / data_len\n",
    "    avg_ber = total_ber / data_len\n",
    "    avg_bler = total_bler / data_len\n",
    "    if ((epoch+1) % 5 == 0):\n",
    "         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, BER: {avg_ber:.4f}, BLER: {avg_bler:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_predictions tensor([[1., 1., 1.]], device='cuda:0')\n",
      "msg_tensor tensor([[1., 0., 1.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[1., 1., 0.]], device='cuda:0')\n",
      "msg_tensor tensor([[1., 1., 0.]], device='cuda:0')\n",
      "decoded correctly\n",
      "----------\n",
      "final_predictions tensor([[0., 1., 1.]], device='cuda:0')\n",
      "msg_tensor tensor([[0., 1., 0.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[0., 1., 1.]], device='cuda:0')\n",
      "msg_tensor tensor([[0., 1., 0.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[0., 1., 1.]], device='cuda:0')\n",
      "msg_tensor tensor([[0., 0., 1.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "Test Results - BER: 0.1767, BLER: 0.4500\n"
     ]
    }
   ],
   "source": [
    "ber_total,bler_total = 0,0\n",
    "test_loader = df['msg_bits'][900:]\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for msg_bits, corrupted_codeword in zip(df['msg_bits'][900:], df['corrupted_codeword'][900:]):\n",
    "        count += 1\n",
    "        msg_tensor = torch.tensor(msg_bits, dtype=torch.float32).to(device)\n",
    "        corrupted_codeword_tensor = torch.tensor(corrupted_codeword, dtype=torch.float32).to(device)\n",
    "\n",
    "        _,final_predictions = model(corrupted_codeword_tensor)\n",
    "        if (count%20==0):\n",
    "            print(f'final_predictions {(final_predictions>=0).float()}')\n",
    "            print(f'msg_tensor {msg_tensor}')\n",
    "            if((final_predictions>0).float()==msg_tensor).all():\n",
    "                print('decoded correctly')\n",
    "            else:\n",
    "                print('decoded incorrectly')\n",
    "            print('----------')\n",
    "        ber,bler = calculate_ber_bler((final_predictions>=0).float(),msg_tensor)\n",
    "        ber_total += ber\n",
    "        bler_total += bler\n",
    "    avg_ber = ber_total / len(test_loader)\n",
    "    avg_bler = bler_total / len(test_loader)\n",
    "    print(f\"Test Results - BER: {avg_ber:.4f}, BLER: {avg_bler:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
