{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from polar import PolarCode,get_frozen\n",
    "from reliability_sequence import Reliability_Sequence\n",
    "from utils import errors_ber,errors_bler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "N = 2**n \n",
    "K = 3\n",
    "snr = 1\n",
    "batch_size = 1\n",
    "num_samples = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data(num_samples, batch_size, n, K, snr):\n",
    "    msg_bits_list = []\n",
    "    bpsk_list = []\n",
    "    codeword_list = []\n",
    "    corrupted_codeword_list = []\n",
    "\n",
    "    # Loop to generate data samples\n",
    "    for i in range(num_samples):\n",
    "        msg_bits = (torch.rand(batch_size, K) > 0.5).float()\n",
    "        bpsk = 1 - 2 * msg_bits\n",
    "\n",
    "        polar = PolarCode(n, K, Fr=None, use_cuda=True, hard_decision=True)\n",
    "        codeword = polar.encode(bpsk)\n",
    "        corrupted_codewords = polar.channel(codeword, snr)\n",
    "\n",
    "        msg_bits_list.append(msg_bits.cpu().numpy())\n",
    "        bpsk_list.append(bpsk.cpu().numpy())\n",
    "        codeword_list.append(codeword.cpu().numpy())\n",
    "        corrupted_codeword_list.append(corrupted_codewords.cpu().numpy())\n",
    "\n",
    "    filename = f\"polar_dataset_N{2**n}_K{K}_SNR{snr}_bs{batch_size}.npz\"\n",
    "    np.savez(f\"polar_dataset_N{2**n}_K{K}_SNR{snr}_bs{batch_size}.npz\", msg_bits=msg_bits_list, corrupted_codeword=corrupted_codeword_list,bpsk = bpsk_list,codeword=codeword_list)\n",
    "    print(f\"Dataset saved as {filename}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as polar_dataset_N8_K3_SNR1_bs1.npz\n"
     ]
    }
   ],
   "source": [
    "create_data(num_samples,batch_size,n,K,snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load('data\\polar_dataset_N8_K3_SNR1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pratyush\\AppData\\Local\\Temp\\ipykernel_18476\\1575160849.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 177.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "Fr = get_frozen(N, K,rs=Reliability_Sequence)\n",
    "polar = PolarCode(n, K, Fr = Fr,use_cuda=False,hard_decision=True)\n",
    "device = 'cpu'\n",
    "ber_SC_total=0\n",
    "bler_SC_total=0\n",
    "x=10000\n",
    "for bpsk_bits, corrupted_codeword in tqdm(zip(df['bpsk'][:x], df['corrupted_codeword'][:x]),total=len(df['bpsk'][:x])):\n",
    "    bpsk_tensor = torch.tensor(bpsk_bits, dtype=torch.float32,device=device)\n",
    "    corrupted_codeword_tensor = torch.tensor(corrupted_codeword, dtype=torch.float32,device=device)\n",
    "\n",
    "    SC_llrs, decoded_SC_msg_bits = polar.sc_decode_new(corrupted_codeword_tensor, snr=snr)\n",
    "    ber_SC = errors_ber(bpsk_tensor,decoded_SC_msg_bits.sign()).item()\n",
    "    bler_SC = errors_bler(bpsk_tensor,decoded_SC_msg_bits.sign()).item()\n",
    "\n",
    "    ber_SC_total+=ber_SC\n",
    "    bler_SC_total+=bler_SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1., -1.]]),\n",
       " tensor([[-0.5889, -1.5760,  0.5610, -1.0886, -0.2946, -2.1059, -1.6572, -2.8287]]),\n",
       " tensor([[ 1.,  1., -1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_SC_msg_bits, corrupted_codeword_tensor, bpsk_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_codeword_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03466666740179062, 0.057)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber_SC_total/len(df['msg_bits'][:x]),bler_SC_total/len(df['msg_bits'][:x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM LOGIC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self,N,K,hidden_size,rs):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.K = K\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.frozen_positions = get_frozen(self.N, self.K, rs)\n",
    "        self.frozen_mask = torch.full((N,), -1, dtype=torch.int8)\n",
    "        # self.frozen_mask = torch.zeros(N,dtype=torch.bool)\n",
    "        self.frozen_mask[self.frozen_positions] = 1\n",
    "        self.lstms = nn.ModuleList([\n",
    "            nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "            for _ in range(N)\n",
    "        ])\n",
    "        self.fcs= nn.ModuleList([\n",
    "            nn.Linear(hidden_size, 1) for _ in range(N)\n",
    "        ])\n",
    "    \n",
    "    def forward(self,corrupted_codeword):\n",
    "        batch_size = corrupted_codeword.size(0)\n",
    "        device = corrupted_codeword.device\n",
    "        x = corrupted_codeword.unsqueeze(-1) if corrupted_codeword.dim() == 2 else corrupted_codeword\n",
    "\n",
    "        h0 = [torch.zeros(1, batch_size, self.hidden_size, device=device) for _ in range(self.N)]\n",
    "        c0 = [torch.zeros(1, batch_size, self.hidden_size, device=device) for _ in range(self.N)]\n",
    "\n",
    "        decoded_outputs = []\n",
    "        for i in range(self.N):\n",
    "            output, (h0[i], c0[i]) = self.lstms[i](x, (h0[i], c0[i]))\n",
    "            print(output.shape)\n",
    "            decoded_bits = self.fcs[i](output).squeeze(-1)\n",
    "            decoded_outputs.append(decoded_bits)\n",
    "            x = corrupted_codeword + (self.frozen_mask.float().to(device)*decoded_bits.sign()) #current logic\n",
    "            x = x.unsqueeze(-1)\n",
    "        \n",
    "        decoded_outputs = torch.stack(decoded_outputs,dim=1)\n",
    "        # non_frozen_mask = ~self.frozen_mask\n",
    "        non_frozen_mask = (self.frozen_mask == -1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        final_predictions = decoded_outputs[:,-1,non_frozen_mask]\n",
    "\n",
    "        return decoded_outputs, final_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM LOGIC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder2(nn.Module):\n",
    "    def __init__(self,N,K,hidden_size,rs):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.K = K\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.frozen_positions = get_frozen(self.N, self.K, rs)\n",
    "        self.frozen_mask = torch.full((N,), 0, dtype=torch.int8)\n",
    "        # self.frozen_mask = torch.zeros(N,dtype=torch.int8)\n",
    "        self.frozen_mask[self.frozen_positions] = 1\n",
    "        self.lstms = nn.ModuleList([\n",
    "            nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "            for _ in range(N)\n",
    "        ])\n",
    "        self.fcs= nn.ModuleList([\n",
    "            nn.Linear(hidden_size+1, 1) for _ in range(N) # 1 for the frozen bit\n",
    "        ])\n",
    "    \n",
    "    def forward(self,corrupted_codeword):\n",
    "        batch_size = corrupted_codeword.size(0)\n",
    "        device = corrupted_codeword.device\n",
    "        x = corrupted_codeword.unsqueeze(-1) if corrupted_codeword.dim() == 2 else corrupted_codeword\n",
    "\n",
    "        h0 = [torch.zeros(1, batch_size, self.hidden_size, device=device) for _ in range(self.N)]\n",
    "        c0 = [torch.zeros(1, batch_size, self.hidden_size, device=device) for _ in range(self.N)]\n",
    "\n",
    "        decoded_outputs = []\n",
    "        for i in range(self.N):\n",
    "            lstm_output, (h0[i], c0[i]) = self.lstms[i](x, (h0[i], c0[i]))\n",
    "\n",
    "            frozen_bit = self.frozen_mask[i].float().to(device) \n",
    "            print(frozen_bit)\n",
    "            frozen_bit = frozen_bit.unsqueeze(0).unsqueeze(0).expand(batch_size, lstm_output.size(1), -1) \n",
    "            print(frozen_bit.shape)           \n",
    "            lstm_output_with_frozen = torch.cat([lstm_output, frozen_bit], dim=-1)\n",
    "            print(lstm_output_with_frozen.shape)\n",
    "            predicted_bit = self.fcs[i](lstm_output_with_frozen).squeeze(-1)\n",
    "            print(predicted_bit.shape)\n",
    "            decoded_outputs.append(predicted_bit)\n",
    "            # x = corrupted_codeword + (self.frozen_mask.float().to(device)*decoded_bits.sign()) #current logic\n",
    "            x = torch.cat([x, predicted_bit.unsqueeze(-1)], dim=-1)[:,:,-1:]\n",
    "            print(F'x_{x.shape}')\n",
    "        \n",
    "        decoded_outputs = torch.stack(decoded_outputs,dim=1)\n",
    "        # non_frozen_mask = ~self.frozen_mask\n",
    "        non_frozen_mask = (self.frozen_mask == 0).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        final_predictions = decoded_outputs[:,-1,non_frozen_mask]\n",
    "\n",
    "        return decoded_outputs, final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = LSTMDecoder2(N=N,K=K,hidden_size=32,rs=Reliability_Sequence).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ber_bler(predictions, targets):\n",
    "    \"\"\" Calculate BER and BLER using errors_ber and errors_bler functions. \"\"\"\n",
    "    ber = errors_ber(targets, predictions.sign()).item()\n",
    "    bler = errors_bler(targets, predictions.sign()).item()\n",
    "    return ber, bler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:12<00:00, 74.35it/s]\n",
      "100%|██████████| 900/900 [00:12<00:00, 73.56it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 79.73it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 81.09it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 79.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 0.6933, BER: 0.4981, BLER: 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:11<00:00, 80.25it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 79.94it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 82.36it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 83.56it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 83.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Loss: 0.6933, BER: 0.4930, BLER: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:11<00:00, 81.28it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 82.32it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 81.55it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 82.09it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 82.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 0.6933, BER: 0.4930, BLER: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:11<00:00, 81.69it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 83.09it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 83.30it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 83.00it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 83.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 0.6932, BER: 0.4930, BLER: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:11<00:00, 81.66it/s]\n",
      "100%|██████████| 900/900 [00:10<00:00, 82.09it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 78.16it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 79.29it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 78.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Loss: 0.6932, BER: 0.4930, BLER: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:11<00:00, 79.10it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 78.89it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 79.57it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 80.91it/s]\n",
      "100%|██████████| 900/900 [00:11<00:00, 79.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.6932, BER: 0.4930, BLER: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "data_len = len(df['msg_bits'][:900])\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_ber,total_bler =0,0\n",
    "    for msg_bits, corrupted_codeword in tqdm(zip(df['msg_bits'][:900], df['corrupted_codeword'][:900]),total=data_len):\n",
    "        msg_tensor = torch.tensor(msg_bits, dtype=torch.float32).to(device)\n",
    "        corrupted_codeword_tensor = torch.tensor(corrupted_codeword, dtype=torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        decoded_outputs, final_predictions = model(corrupted_codeword_tensor)\n",
    "        loss = criterion(final_predictions,msg_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+= loss.item()\n",
    "\n",
    "        ber, bler = calculate_ber_bler((final_predictions>=0).float(), msg_tensor)\n",
    "        total_ber += ber\n",
    "        total_bler += bler\n",
    "    avg_loss = total_loss / data_len\n",
    "    avg_ber = total_ber / data_len\n",
    "    avg_bler = total_bler / data_len\n",
    "    if ((epoch+1) % 5 == 0):\n",
    "         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, BER: {avg_ber:.4f}, BLER: {avg_bler:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_predictions tensor([[0., 0., 0.]], device='cuda:0')\n",
      "msg_tensor tensor([[1., 0., 1.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[0., 0., 0.]], device='cuda:0')\n",
      "msg_tensor tensor([[1., 1., 0.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[0., 0., 0.]], device='cuda:0')\n",
      "msg_tensor tensor([[0., 1., 0.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[0., 0., 0.]], device='cuda:0')\n",
      "msg_tensor tensor([[0., 1., 0.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "final_predictions tensor([[0., 0., 0.]], device='cuda:0')\n",
      "msg_tensor tensor([[0., 0., 1.]], device='cuda:0')\n",
      "decoded incorrectly\n",
      "----------\n",
      "Test Results - BER: 0.4967, BLER: 0.8700\n"
     ]
    }
   ],
   "source": [
    "ber_total,bler_total = 0,0\n",
    "test_loader = df['msg_bits'][900:]\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for msg_bits, corrupted_codeword in zip(df['msg_bits'][900:], df['corrupted_codeword'][900:]):\n",
    "        count += 1\n",
    "        msg_tensor = torch.tensor(msg_bits, dtype=torch.float32).to(device)\n",
    "        corrupted_codeword_tensor = torch.tensor(corrupted_codeword, dtype=torch.float32).to(device)\n",
    "\n",
    "        _,final_predictions = model(corrupted_codeword_tensor)\n",
    "        if (count%20==0):\n",
    "            print(f'final_predictions {(final_predictions>=0).float()}')\n",
    "            print(f'msg_tensor {msg_tensor}')\n",
    "            if((final_predictions>0).float()==msg_tensor).all():\n",
    "                print('decoded correctly')\n",
    "            else:\n",
    "                print('decoded incorrectly')\n",
    "            print('----------')\n",
    "        ber,bler = calculate_ber_bler((final_predictions>=0).float(),msg_tensor)\n",
    "        ber_total += ber\n",
    "        bler_total += bler\n",
    "    avg_ber = ber_total / len(test_loader)\n",
    "    avg_bler = bler_total / len(test_loader)\n",
    "    print(f\"Test Results - BER: {avg_ber:.4f}, BLER: {avg_bler:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
